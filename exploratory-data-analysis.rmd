<div style="font-family: monospace;text-align: center;border: 1px solid black;padding-top: 5px; padding-bottom: 5px">
   <span style="float: left;padding-left: 20px">Where are the crimes?</span>
   <span style="align: center">STATS 765</span>
   <span style="float: right;padding-right: 20px">243337734</span>
</div>
<br/>

# STATS 765: Project - Exploratory Data Analysis

## Setup

```{r setup, include=FALSE}
library("tidyverse")
path <- "~/Documents/Workspace/2025-s2-stats-765/data"
```

## Load all files
`
Special Values:

| Value  | Meaning                           |
| ------ | --------------------------------- |
| `-997` | Data not collected                |
| `-999` | Suppressed due to confidentiality |

```{r load-files, cache = TRUE}
df_victimizations <- read_csv(
    paste(path, "/victimizations-data.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
df_census <- read_csv(
    paste(path, "/2023_Census_totals_by_topic_for_households_by_SA2.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
df_meshblock <- read_csv(
    paste(path, "/meshblock-higher-geographies-2023-generalized.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
dim(df_census)
dim(df_meshblock)
dim(df_victimizations)
```

## Cleanup

### Victimizations

```{r cleanup-victimizations, cache = TRUE}
# Find all columns which only have 1 distinct value.
single_value_column_names <- df_victimizations |>
    summarize(across(everything(), ~ n_distinct(.))) |>
    # This anonymous function keeps only those columns in the tibble which have value = 1.
    select(where(~ 1 == .x)) |>
    names()

# Remove these columns.
df_victimizations <- df_victimizations |>
    select(-all_of(single_value_column_names))

# Year Month and Year Month (copy 2) likely to contain the same values.
print(
    df_victimizations |>
        select(c(`Year Month`, `Year Month (copy 2)`)) |>
        mutate(diff = `Year Month` != `Year Month (copy 2)`) |>
        filter(diff == TRUE) |>
        summarize(n = n())
)

# Since the above returns a 0 count, drop that column.
df_victimizations <- df_victimizations |> select(-`Year Month (copy 2)`)

# Final list of columns
colnames(df_victimizations)
```

### Meshblock

```{r cleanup-meshblock, cache = TRUE}
colnames(df_meshblock)
df_meshblock <- df_meshblock |>
    # This dataset is to just join the two datasets, so drop any excess columns.
    select(c(MB2023_V1_00, SA22023_V1_00, SA22023_V1_00_NAME)) |>
    # The meshblock is a string here, so it needs to be converted to a numeric column before joining.
    mutate(Meshblock = as.numeric(MB2023_V1_00)) |> # Rename it to Meshblock for ease of joining.
    select(-MB2023_V1_00)

# Unlikely to have columns that only have 1 distinct values in this data, check anyway.
print(
    df_meshblock |>
        summarize(across(everything(), ~ n_distinct(.))) |>
        # This anonymous function keeps only those columns in the tibble which have value = 1.
        select(where(~ 1 == .x)) |>
        names()
) # Returns nothing.
```

### Census

```{r cleanup-census, cache = TRUE}
# The column names are excessively long, shorten them for readability.

df_census <- df_census |>
    rename_with(
        ~ .x |>
            str_replace("Subject pop: Households in rented occupied private dwellings, Year: ", "Rentals - ") |>
            str_replace("Subject pop: Households in occupied private dwellings, Year: ", "Households - ") |>
            str_replace(", Measure: Count, Var1:", " -") |>
            str_replace(", Measure: Median, Var1: ", " - Median: ") |>
            str_replace(", Measure: Mean, Var1: ", " - Median: ") |>
            str_replace(" paid by household", "") |>
            str_replace("Total household income", "Income") |>
            str_replace("Sector of landlord", "Landlord") |>
            str_replace("Tenure of household", "Tenure") |>
            str_replace("Number of usual residents in household", "# of Residents") |>
            str_replace("Household crowding index", "Crowding Index") |>
            str_replace("Household composition", "Composition") |>
            str_replace("Access to telecommunication systems", "Telecom Access") |>
            str_replace("Number of motor vehicles", "Vehicle Count") |>
            str_replace("Count of households in occupied private dwellings", "Household Count")
    )

single_value_colnames_census <- df_census |>
    summarize(across(everything(), ~ n_distinct(.))) |>
    # This anonymous function keeps only those columns in the tibble which have value = 1.
    select(where(~ 1 == .x)) |>
    names()

# Determine the distinct values available for these columns.
print(
    df_census |>
        select(all_of(single_value_colnames_census)) |>
        distinct() |>
        as.data.frame()
)

# Since all of these are NA values, meaning the data is not available, we remove these columns.
df_census <- df_census |>
    select(-all_of(single_value_colnames_census))
```

## Join Datasets

```{r join-all, cache = TRUE}
df_merge <- inner_join(
    df_census,
    inner_join(
        df_victimizations, df_meshblock,
        by = "Meshblock"
    ),
    by = c("Statistical area 2 (SA2) 2023 code" = "SA22023_V1_00")
)
dim(df_merge)
```

## Visualizations

### Distribution of Committed Offenses
```{r visualization-1, cache=TRUE}
# Most committed offenses
df_merge |>
    group_by(`ANZSOC Division`) |>
    summarize(count_by_subdivision = n(), .groups = "drop") |>
    # slice_max(n = 10, order_by = count_by_subdivision) |>
    ggplot(aes(x = "", y = count_by_subdivision, fill = `ANZSOC Division`)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    labs(
        title = "Distribution of Committed Offenses",
        x = "",
        y = ""
    )
```

### Criminal Activity Hotspots
```{r visualization-2}
# Areas with a high prevalence of crime
knitr::kable(
    df_merge |>
        group_by(SA22023_V1_00_NAME) |>
        summarize(count_by_sa2 = n(), .groups = "drop") |>
        slice_max(n = 10, order_by = count_by_sa2),
    col.names = c("Statistical Area 2 Name", "Number of offenses")
)
```

### Overall Crime Rate / 1000 Households in Large Areas
```{r visualization-3}
total_number_of_households <- sum(df_merge$`Households - 2023 - Household Count (Total)`)
# Consider a 0.1% of the total household count as the threshold to identify large SA2s.
threshold <- total_number_of_households * 0.001

knitr::kable(
    df_merge |>
        # Filter all NAs
        filter(
            !is.na(Victimisations),
            !is.na(`Households - 2023 - Household Count (Total)`)
        ) |>
        group_by(
            `Statistical area 2 (SA2) 2023 code`,
            `Statistical area 2 (SA2) 2023 name`
        ) |>
        summarize(
            total_victimisations = sum(Victimisations),
            households = sum(`Households - 2023 - Household Count (Total)`),
            .groups = "drop"
        ) |>
        filter(households > threshold) |>
        mutate(
            # Crime rate per 1,000 households
            crime_rate_per_1000hh = (total_victimisations / households) * 1000
        ) |>
        select(-`Statistical area 2 (SA2) 2023 code`) |>
        arrange(desc(crime_rate_per_1000hh)) |>
        head(n = 10),
    col.names = c("SA2 Name", "Victimizations", "Households", "CR / 1000 HH")
)
```

### Crime Rate / 1000 Households - Household Income (< $20,000)

```{r visualization-4}
df_income_crime <- df_merge |>
    # Filter all NAs
    filter(
        !is.na(Victimisations),
        !is.na(`Households - 2023 - Income ($20,000 or less)`),
        !is.na(`Households - 2023 - Income (Total stated)`),
        !is.na(`Households - 2023 - Household Count (Total)`),
    ) |>
    group_by(
        `Statistical area 2 (SA2) 2023 code`,
        `Statistical area 2 (SA2) 2023 name`
    ) |>
    summarize(
        total_victimisations = sum(Victimisations),
        low_income_count = first(`Households - 2023 - Income ($20,000 or less)`),
        total_income_count = first(`Households - 2023 - Income (Total stated)`),
        households = first(`Households - 2023 - Household Count (Total)`),
        .groups = "drop"
    ) |>
    mutate(
        # Ratio of households earning $20k or less
        low_income_ratio = low_income_count * 100 / total_income_count,
        # Crime rate per 1,000 households
        crime_rate_per_1000hh = (total_victimisations / households) * 1000
    )

# Better correlation
cor.test(
    df_income_crime$crime_rate_per_1000hh,
    df_income_crime$low_income_ratio
)

knitr::kable(
    df_income_crime |>
        select(
            `Statistical area 2 (SA2) 2023 name`,
            low_income_ratio,
            households,
            crime_rate_per_1000hh
        ) |>
        arrange(desc(low_income_ratio)) |>
        head(n = 20),
    col.names = c("Statistical Area 2", "% of low income HH", "Households", "Victimizations / 1000 HH")
)
```

### Crime Rate / 1000 Households - Crowding

```{r visualization-5}
df_income_crime <- df_merge |>
    # Filter all NAs
    filter(
        !is.na(Victimisations),
        !is.na(`Households - 2023 - Income ($20,000 or less)`),
        !is.na(`Households - 2023 - Income (Total stated)`),
        !is.na(`Households - 2023 - Household Count (Total)`),
    ) |>
    group_by(
        `Statistical area 2 (SA2) 2023 code`,
        `Statistical area 2 (SA2) 2023 name`
    ) |>
    summarize(
        total_victimisations = sum(Victimisations),
        low_income_count = first(`Households - 2023 - Income ($20,000 or less)`),
        total_income_count = first(`Households - 2023 - Income (Total stated)`),
        households = first(`Households - 2023 - Household Count (Total)`),
        .groups = "drop"
    ) |>
    mutate(
        # Ratio of households earning $20k or less
        low_income_ratio = low_income_count * 100 / total_income_count,
        # Crime rate per 1,000 households
        crime_rate_per_1000hh = (total_victimisations / households) * 1000
    )

# Better correlation
cor.test(
    df_income_crime$crime_rate_per_1000hh,
    df_income_crime$low_income_ratio
)

knitr::kable(
    df_income_crime |>
        select(
            `Statistical area 2 (SA2) 2023 name`,
            low_income_ratio,
            households,
            crime_rate_per_1000hh
        ) |>
        arrange(desc(low_income_ratio)) |>
        head(n = 20),
    col.names = c("Statistical Area 2", "% of low income HH", "Households", "Victimizations / 1000 HH")
)
```
