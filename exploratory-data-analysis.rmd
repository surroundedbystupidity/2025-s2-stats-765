<div style="font-family: monospace;text-align: center;border: 1px solid black;padding-top: 5px; padding-bottom: 5px">
   <span style="float: left;padding-left: 20px">Where are the crimes?</span>
   <span style="align: center">STATS 765</span>
   <span style="float: right;padding-right: 20px">243337734</span>
</div>
<br/>

# STATS 765: Project - Exploratory Data Analysis

## Setup

```{r include=FALSE}
library("tidyverse")
path <- "~/Documents/Workspace/2025-s2-stats-765/data"
```

## Load all files.
```{r cache = TRUE}
df_victimizations <- read_csv(
    paste(path, "/victimizations-data.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
df_census <- read_csv(
    paste(path, "/2023_Census_totals_by_topic_for_households_by_SA2.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
df_meshblock <- read_csv(
    paste(path, "/meshblock-higher-geographies-2023-generalized.csv", sep = ""),
    na = c("", "NA", -999, -997), show_col_types = FALSE
)
dim(df_census)
dim(df_meshblock)
dim(df_victimizations)
```

## Cleanup

### Victimizations

```{r cache = TRUE}
# Find all columns which only have 1 distinct value.
single_value_column_names <- df_victimizations |>
    summarize(across(everything(), ~ n_distinct(.))) |>
    # This anonymous function keeps only those columns in the tibble which have value = 1.
    select(where(~ 1 == .x)) |>
    names()

# Remove these columns.
df_victimizations <- df_victimizations |>
    select(-all_of(single_value_column_names))

# Year Month and Year Month (copy 2) likely to contain the same values.
print(
    df_victimizations |>
        select(c(`Year Month`, `Year Month (copy 2)`)) |>
        mutate(diff = `Year Month` != `Year Month (copy 2)`) |>
        filter(diff == TRUE) |>
        summarize(n = n())
)

# Since the above returns a 0 count, drop that column.
df_victimizations <- df_victimizations |> select(-`Year Month (copy 2)`)

# Final list of columns
colnames(df_victimizations)
```

### Meshblock

```{r cache = TRUE}
colnames(df_meshblock)
df_meshblock <- df_meshblock |>
    # This dataset is to just join the two datasets, so drop any excess columns.
    select(c(MB2023_V1_00, SA22023_V1_00, SA22023_V1_00_NAME)) |>
    # The meshblock is a string here, so it needs to be converted to a numeric column before joining.
    mutate(Meshblock = as.numeric(MB2023_V1_00)) |> # Rename it to Meshblock for ease of joining.
    select(-MB2023_V1_00)

# Unlikely to have columns that only have 1 distinct values in this data, check anyway.
print(
    df_meshblock |>
        summarize(across(everything(), ~ n_distinct(.))) |>
        # This anonymous function keeps only those columns in the tibble which have value = 1.
        select(where(~ 1 == .x)) |>
        names()
) # Returns nothing.
```

### Census

Special Values:

| Value  | Meaning                           |
| ------ | --------------------------------- |
| `-997` | Data not collected                |
| `-999` | Suppressed due to confidentiality |

```{r cache = TRUE}
# The column names are excessively long, shorten them for readability.

df_census <- df_census |>
    rename_with(
        ~ .x |>
            str_replace("Subject pop: Households in rented occupied private dwellings, Year: ", "Rentals - ") |>
            str_replace("Subject pop: Households in occupied private dwellings, Year: ", "Households - ") |>
            str_replace(", Measure: Count, Var1:", " -") |>
            str_replace(", Measure: Median, Var1: ", " - Median: ") |>
            str_replace(", Measure: Mean, Var1: ", " - Median: ") |>
            str_replace(" paid by household", "") |>
            str_replace("Total household income", "Income") |>
            str_replace("Sector of landlord", "Landlord") |>
            str_replace("Tenure of household", "Tenure") |>
            str_replace("Number of usual residents in household", "# of Residents") |>
            str_replace("Household crowding index", "Crowding Index") |>
            str_replace("Household composition", "Composition") |>
            str_replace("Access to telecommunication systems", "Telecom Access") |>
            str_replace("Number of motor vehicles", "Vehicle Count") |>
            str_replace("Count of households in occupied private dwellings", "Household Count")
    )

single_value_colnames_census <- df_census |>
    summarize(across(everything(), ~ n_distinct(.))) |>
    # This anonymous function keeps only those columns in the tibble which have value = 1.
    select(where(~ 1 == .x)) |>
    names()

# Determine the distinct values available for these columns.
print(
    df_census |>
        select(all_of(single_value_colnames_census)) |>
        distinct() |>
        as.data.frame()
)

# Since all of these are NA values, meaning the data is not available, we remove these columns.
df_census <- df_census |>
    select(-all_of(single_value_colnames_census))
```

## Join Datasets

```{r cache = TRUE}
df_merge <- inner_join(
    df_census,
    inner_join(
        df_victimizations, df_meshblock,
        by = "Meshblock"
    ),
    by = c("Statistical area 2 (SA2) 2023 code" = "SA22023_V1_00")
)
dim(df_merge)
```

## Visualizations

### Distribution of Committed Offenses
```{r}
# Most committed offenses
df_merge |>
    group_by(`ANZSOC Division`) |>
    summarize(count_by_subdivision = n(), .groups = "drop") |>
    # slice_max(n = 10, order_by = count_by_subdivision) |>
    ggplot(aes(x = "", y = count_by_subdivision, fill = `ANZSOC Division`)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    labs(
        title = "Distribution of Committed Offenses",
        x = "",
        y = ""
    )
```

### Criminal Activity Hotspots
```{r}
# Areas with a high prevalence of crime
knitr::kable(
    df_merge |>
        group_by(SA22023_V1_00_NAME) |>
        summarize(count_by_sa2 = n(), .groups = "drop") |>
        slice_max(n = 10, order_by = count_by_sa2),
    col.names = c("Statistical Area 2 Name", "Number of offenses")
)
```

### Crime Rate / 1000 Households - Median Income
```{r}
df_analysis <- df_merge |>
    filter(
        !is.na(Victimisations),
        !is.na(`Households - 2023 - Median: Income (Median ($))`),
        !is.na(`Households - 2023 - Household Count (Total)`)
    ) |>
    # Group by SA2 and year to aggregate crimes
    group_by(`Statistical area 2 (SA2) 2023 code`, `Statistical area 2 (SA2) 2023 name`) |>
    summarize(
        total_victimisations = sum(Victimisations),
        median_income = first(`Households - 2023 - Median: Income (Median ($))`),
        households = first(`Households - 2023 - Household Count (Total)`)
    ) |>
    ungroup() |>
    # Calculate crime rate per 1,000 households
    mutate(
        crime_rate_per_1000hh = (total_victimisations / households) * 1000
    )

# Weak correlation.
cor_test <- cor.test(df_analysis$crime_rate_per_1000hh, df_analysis$median_income, use = "complete.obs")

df_analysis |>
    select(`Statistical area 2 (SA2) 2023 name`, median_income, crime_rate_per_1000hh) |>
    arrange(desc(crime_rate_per_1000hh))

ggplot(df_analysis, aes(x = median_income, y = crime_rate_per_1000hh)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE) +
    labs(
        title = "Crime Rate vs Median Household Income by SA2",
        x = "Median Household Income",
        y = "Crime Rate per 1000 Households"
    )
```

### Crime Rate / 1000 Households - Household Income (< $20,000)

```{r}
df_income_crime <- df_merge |>
    # Keep only rows with no missing values for key fields
    filter(
        !is.na(Victimisations),
        !is.na(`Households - 2023 - Income ($20,000 or less)`),
        !is.na(`Households - 2023 - Income (Total stated)`),
        !is.na(`Households - 2023 - Household Count (Total)`)
    ) |>
    group_by(
        `Statistical area 2 (SA2) 2023 code`,
        `Statistical area 2 (SA2) 2023 name`
    ) |>
    summarize(
        total_victimisations = sum(Victimisations),
        low_income_count = first(`Households - 2023 - Income ($20,000 or less)`),
        total_income_count = first(`Households - 2023 - Income (Total stated)`),
        households = first(`Households - 2023 - Household Count (Total)`),
        .groups = "drop"
    ) |>
    mutate(
        # Ratio of households earning $20k or less
        prop_low_income = low_income_count / total_income_count,
        # Crime rate per 1,000 households
        crime_rate_per_1000hh = (total_victimisations / households) * 1000
    )

# Correlation
cor_test_income <- cor.test(
    df_income_crime$crime_rate_per_1000hh,
    df_income_crime$prop_low_income
)

df_income_crime |>
    select(`Statistical area 2 (SA2) 2023 name`, prop_low_income, crime_rate_per_1000hh) |>
    arrange(desc(prop_low_income))


ggplot(df_income_crime, aes(x = prop_low_income, y = crime_rate_per_1000hh)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE) +
    labs(
        title = "Crime Rate vs Low Household Income Proportion by SA2",
        x = "Median Household Income",
        y = "Crime Rate per 1000 Households"
    )
```